{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04cd61c-acf3-494b-a377-34cc2bacd342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blood Transfusion Service Center dataset example \n",
      "\n",
      "Creating 4-(8-8)-1 binary NN classifier \n",
      "\n",
      "epoch =    0  loss = 0.620762  acc = 0.76%\n",
      "epoch =  250  loss = 0.474905  acc = 0.77%\n",
      "epoch =  500  loss = 0.471545  acc = 0.78%\n",
      "epoch =  750  loss = 0.471464  acc = 0.78%\n",
      "epoch = 1000  loss = 0.470742  acc = 0.78%\n",
      "epoch = 1250  loss = 0.470404  acc = 0.78%\n",
      "epoch = 1500  loss = 0.470032  acc = 0.79%\n",
      "epoch = 1750  loss = 0.468633  acc = 0.79%\n",
      "epoch = 2000  loss = 0.467279  acc = 0.79%\n",
      "epoch = 2250  loss = 0.465817  acc = 0.80%\n",
      "epoch = 2500  loss = 0.464320  acc = 0.79%\n",
      "epoch = 2750  loss = 0.463318  acc = 0.79%\n",
      "epoch = 3000  loss = 0.462272  acc = 0.79%\n",
      "epoch = 3250  loss = 0.461578  acc = 0.79%\n",
      "epoch = 3500  loss = 0.461547  acc = 0.79%\n",
      "epoch = 3750  loss = 0.461139  acc = 0.79%\n",
      "epoch = 4000  loss = 0.460199  acc = 0.79%\n",
      "epoch = 4250  loss = 0.460235  acc = 0.79%\n",
      "epoch = 4500  loss = 0.459801  acc = 0.80%\n",
      "epoch = 4750  loss = 0.459402  acc = 0.79%\n",
      "\n",
      "Loss, accuracy on test data: \n",
      "0.5370 73.30%\n",
      "\n",
      "Predicting authenticity for: \n",
      "[[0.5 0.5 0.5 0.5]]\n",
      "Probability that class = 1 ( he/she donated blood in March 2007):\n",
      "[[0.1198]]\n"
     ]
    }
   ],
   "source": [
    "# Blood Transfusion Service Center\n",
    "# raw data looks like:\n",
    "# 2,50,12500,98,1\n",
    "# 1 stand for donating blood; 0 stands for not donating blood\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.keras as K\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'  # suppress CPU msg\n",
    "\n",
    "class MyLogger(K.callbacks.Callback):\n",
    "  def __init__(self, n):\n",
    "    self.n = n   # print loss & acc every n epochs\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if epoch % self.n == 0:\n",
    "      curr_loss =logs.get('loss')\n",
    "      curr_acc = logs.get('accuracy') \n",
    "      print(\"epoch = %4d  loss = %0.6f  acc = %0.2f%%\" % \\\n",
    "        (epoch, curr_loss, curr_acc))\n",
    "\n",
    "def main():\n",
    "  print(\"\\nBlood Transfusion Service Center dataset example \\n\")\n",
    "  np.random.seed(1)\n",
    "\n",
    "  # 1. load data\n",
    "  # print(\"Loading data into memory \")\n",
    "  train_file = \"C:/Users/Ioana/Desktop/IA/transfusion_train.data\"\n",
    "  test_file = \"C:/Users/Ioana/Desktop/IA/transfusion_test.data\"\n",
    "\n",
    "  train_x_nenorm = np.loadtxt(train_file, delimiter=',', usecols=[0,1,2,3], dtype=np.float32)\n",
    "  col0_norm = (train_x_nenorm[:,0]-min(train_x_nenorm[:,0])) / (max(train_x_nenorm[:,0])-min(train_x_nenorm[:,0]))\n",
    "  col1_norm = (train_x_nenorm[:,1]-min(train_x_nenorm[:,1])) / (max(train_x_nenorm[:,1])-min(train_x_nenorm[:,1]))\n",
    "  col2_norm = (train_x_nenorm[:,2]-min(train_x_nenorm[:,2])) / (max(train_x_nenorm[:,2])-min(train_x_nenorm[:,2]))\n",
    "  col3_norm = (train_x_nenorm[:,3]-min(train_x_nenorm[:,3])) / (max(train_x_nenorm[:,3])-min(train_x_nenorm[:,3]))\n",
    "  train_x=np.stack((col0_norm,col1_norm,col2_norm,col3_norm),axis=1)\n",
    "  train_y = np.loadtxt(train_file, delimiter=',',\n",
    "    usecols=[4], dtype=np.float32)\n",
    "  test_x_nenorm = np.loadtxt(test_file, delimiter=',', \n",
    "    usecols=[0,1,2,3], dtype=np.float32)\n",
    "  col0_norm1 = (test_x_nenorm[:,0]-min(test_x_nenorm[:,0])) / (max(test_x_nenorm[:,0])-min(test_x_nenorm[:,0]))\n",
    "  col1_norm1 = (test_x_nenorm[:,1]-min(test_x_nenorm[:,1])) / (max(test_x_nenorm[:,1])-min(test_x_nenorm[:,1]))\n",
    "  col2_norm1 = (test_x_nenorm[:,2]-min(test_x_nenorm[:,2])) / (max(test_x_nenorm[:,2])-min(test_x_nenorm[:,2]))\n",
    "  col3_norm1 = (test_x_nenorm[:,3]-min(test_x_nenorm[:,3])) / (max(test_x_nenorm[:,3])-min(test_x_nenorm[:,3]))\n",
    "  test_x=np.stack((col0_norm1,col1_norm1,col2_norm1,col3_norm1),axis=1)\n",
    "  test_y =np.loadtxt(test_file, delimiter=',',\n",
    "    usecols=[4], dtype=np.float32)\n",
    "\n",
    "  # 2. define 4-(x-x)-1 deep NN model\n",
    "  print(\"Creating 4-(8-8)-1 binary NN classifier \\n\")\n",
    "  my_init = K.initializers.glorot_uniform(seed=1)\n",
    "  model = K.models.Sequential()\n",
    "  model.add(K.layers.Dense(units=8, input_dim=4,\n",
    "    activation='tanh', kernel_initializer=my_init)) \n",
    "  model.add(K.layers.Dense(units=8, activation='tanh',\n",
    "    kernel_initializer=my_init)) \n",
    "  model.add(K.layers.Dense(units=1, activation='sigmoid',\n",
    "    kernel_initializer=my_init)) \n",
    "\n",
    "  # 3. compile model\n",
    "  simple_sgd = K.optimizers.SGD(learning_rate=0.01)  \n",
    "  model.compile(loss='binary_crossentropy',\n",
    "    optimizer=simple_sgd, metrics=['accuracy'])  \n",
    "\n",
    "  # 4. train model\n",
    "  max_epochs = 5000\n",
    "  my_logger = MyLogger(n=250)\n",
    "  h = model.fit(train_x, train_y, batch_size=32,\n",
    "    epochs=max_epochs, verbose=0, callbacks=[my_logger]) \n",
    "\n",
    "  # 5. evaluate model\n",
    "  np.set_printoptions(precision=4, suppress=True)\n",
    "  eval_results = model.evaluate(test_x, test_y, verbose=0) \n",
    "  print(\"\\nLoss, accuracy on test data: \")\n",
    "  print(\"%0.4f %0.2f%%\" % (eval_results[0], \\\n",
    "eval_results[1]*100))\n",
    "\n",
    "  # 6. save model\n",
    "  # mp = \".\\\\Models\\\\banknote_model.h5\"\n",
    "  # model.save(mp)\n",
    "\n",
    "  # 7. make a prediction\n",
    "  inpts = np.array([[0.5,0.5,0.5,0.5]], dtype=np.float32)\n",
    "  pred = model.predict(inpts)\n",
    "  print(\"\\nPredicting authenticity for: \")\n",
    "  print(inpts)\n",
    "  print(\"Probability that class = 1 ( he/she donated blood in March 2007):\")\n",
    "  print(pred)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb5dcde-8fe3-4b86-9d37-69a967825984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da1699-1a19-4fd1-a85a-01e00b34cd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d401d0-808d-455c-a9c3-647cd327e582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
